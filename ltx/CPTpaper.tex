% journal,10pt,draftclsnofoot,onecolumn
% \documentclass[journal,11pt,a4paper,onecolumn,draftcls]{IEEEtran}
% \documentclass[a4paper]{IEEEtran}
\documentclass[11pt,draftcls,onecolumn]{IEEEtran}
\usepackage{graphicx, algorithm, algorithmicx, algpseudocode}
\usepackage{color}                    % For creating coloured text and background
\usepackage{amsmath,amssymb,amsfonts,epsfig} % Typical maths resource packages
\usepackage{subfigure}

\hyphenation{op-tical net-works semi-conduc-tor}
% TODO environment
\newcommand{\todo}[1]{\textsf{\emph{\textbf{\textcolor{blue}{#1}}}}}
\newcommand{\dean}[1]{\textsf{\emph{\textbf{\textcolor{green}{#1}}}}} 
\newcommand{\levin}[1]{\textsf{\emph{\textbf{\textcolor{red}{#1}}}}} 

\begin{document}

% can use linebreaks \\ within to get better formatting as desired
\title{The Circular Phase Transform for Estimation of Instantaneous Amplitude, Phase, and Frequency}

\author{Dean~R.~Freestone,~\IEEEmembership{Graduate Student Member,~IEEE,}
		David~B.~Grayden,~\IEEEmembership{Member,~IEEE,}
        Alan~Lai,
        Levin~Kuhlman,~\IEEEmembership{Member,~IEEE,}
        Timothy~S.~Nelson,
        Mark~J.~Cook,
        and Anthony~N.~Burkitt,~\IEEEmembership{Senior Member,~IEEE.}
        
\thanks{D.\ R.\ Freestone, D.\ B.\ Grayden, L.\ Kulhman and A.\ N.\ Burkitt are with the Department
of Electrical and Electronic Engineering, University of Melbourne, VIC 3010, Australia {\tt\small dfreestone@bionicear.org}.}  
\thanks{D.\ R.\ Freestone, D.\ B.\ Grayden, A.\ Lai, T.\ S.\ Nelson, M.\ J.\ Cook and A.\ N.\ Burkitt are with The Bionic Ear Institute, 384-388 Albert Street, East Melbourne, VIC 3002, Australia}
\thanks{M.\ J.\ Cook is with the Department of Clinical Neurology, St. Vincent's Hospital, Fitzroy, VIC 3065, Australia}

\thanks{Manuscript received Month Day, Year; revised Month Day, Year.}}

% The paper headers
\markboth{Submitted to IEEE Transactions on Signal Processing}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}

\maketitle

\begin{abstract}
This paper introduces the circular phase transform (CPT), a new method for estimation of the instantaneous phase, frequency and amplitude from broadband, nonstationary oscillatory signals. Conceptually, the CPT is similar to the Hilbert-Huang transform (HHT), where the instantaneous properties are estimated from a signal that has been adaptively demodulated. The CPT performs an adaptive demodulation of the analytic signal in the complex-plane using a circle fitting method. A comparison in estimation accuracy is made between the CPT and the HHT. The CPT provides a more local estimate of the instantaneous properties than the HHT, yielding more accurate results. The CPT may also be used in an empirical mode decomposition.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
Time-frequency analysis, nonlinear signal processing, Hilbert-Huang transform.
\end{IEEEkeywords}

\IEEEpeerreviewmaketitle

\section{Introduction}
\IEEEPARstart{T}{he} term of instantaneous frequency (IF) may seem an oxymoron. If frequency is defined as the number of repeating events per unit time, then it is difficult to conceptualize it as an instantaneous entity. For smooth and continuous oscillatory signals, the IF can be thought of as an extension to the Fourier frequency, where frequency is estimated using the rate of change of the instantaneous phase (IP), and the phase is defined as the entire argument of a cosine or sine function. In the case of a stationary sinusoid, the IP is increasing at a constant rate and the IF is equivalent to the Fourier frequency. In general, the derivative of the instantaneous phase (IP) is the best estimate of the frequency at any point in time. By defining the IF as the derivative of the IP, time-frequency properties of nonstationary, frequency modulated signals, such as chirps, can be estimated. 

To demonstrate the procedure for calculating instantaneous amplitude (IA), instantaneous phase (IP), and instantaneous frequency (IF), we first consider a signal, where all oscillations are centered at the origin, described by
\begin{equation}
	y(t) = r(t)\cos(\phi(t)),
\end{equation}
where $r(t)$ is the IA and $\phi(t)$ is the IP. The IA, IP, and IF can be estimated using the Hilbert transform, where the Hilbert transform of the signal $y(t)$ is defined as
\begin{equation}\label{eq:HilbertTransform}
	\mathcal{H}y\left( t \right) \triangleq \textrm{p.v.}\int\limits_{ - \infty }^\infty  {y\left( \tau  \right)h\left( {t - \tau } \right)} d\tau,
\end{equation}
where $\textrm{p.v.}$ denotes the Cauchy principal value integral and the Hilbert kernel is defined as
\begin{equation}\label{eq:HilbertKernel}
	h\left( t \right) \triangleq {\left( {\pi t} \right)^{ - 1}}.
\end{equation}
For sinusoidal signals, the Hilbert transform is a $\pi/2$ phase shifter, where a cosine function is transformed to a sine.

The analytic signal, $z(t)$, is defined as
\begin{align}\label{eq:AnalyticSignal}
	z\left( t \right) &\triangleq y\left( t \right) + j\mathcal{H}y\left( t \right) \\
    &= r\left( t \right)\left(\cos\left(\phi\left(t\right)\right) + j \mathcal{H}\cos\left(\phi\left(t\right)\right)\right) \\
&= r\left( t \right){e^{j\phi \left( t \right)}},
\end{align}
where $j=\sqrt{-1}$. The IA, IP, and IF are, respectively, defined as
\begin{align}
	r(t) &\triangleq \sqrt{\left(y^2(t) + \mathcal{H}y^2(t)\right)}\label{eq:IAdef}\\
	\phi(t) &\triangleq \arctan\left(\frac{\mathcal{H}y\left( t \right)}{y\left(t\right)}\right) \label{eq:IPdef}\\
\omega \left( t \right) &\triangleq \frac{d\phi \left( t \right)}{dt}. \label{eq:IFdef}
\end{align}

The IA, IP, and IF of this class of signal can be uniquely defined if the conditions of the Bedrosian theorem~\cite{Bedrosian1963} are met, namely
\begin{equation}\label{eq:BedrosianCondition}
\begin{array}{*{20}{c}}
   {\mathcal{F}\left\{ {r\left( t \right)} \right\} = 0,} & {\,\left| \omega \right| > \omega_1,}  \\
   {\mathcal{F}\left\{ {\cos\left(\phi \left( t \right)\right)} \right\} = 0,} & {\left| \omega \right| < \omega_2,}  \\
\end{array}
\end{equation}
where $\mathcal{F}$ denotes the Fourier transform, $\omega$ denotes frequency where $\omega_2 \ge \omega_1 \ge 0$. Eq.~\ref{eq:BedrosianCondition} states that the spectra of the IA and IP components of the signal must be disjoint, for unique definition of the instantaneous properties. It can be interpreted as stating that the IA must be varying on a slower time-scale than the IP component. When these conditions are satisfied, the IP and IA components are separable such that
\begin{align}\label{eq:SepAmpandPhase}
   \mathcal{H}y\left( t \right) &= \mathcal{H}\left\{ {r\left( t \right)\cos \left( {\phi \left( t \right)} \right)} \right\} \nonumber \\
   &= r\left( t \right)\mathcal{H}\left\{ {\cos \left( {\phi \left( t \right)} \right)} \right\}.
\end{align}
These conditions do not, however, guarantee that $r\left(t\right)\cos(\phi(t))$ and $r\left(t\right)\mathcal{H}\{\cos(\phi(t))\}$ form a quadrature pair (phase shifted by $\pi/2$) when the instantaneous frequency or instantaneous amplitude are not constant~\cite{Nuttall1966}, which complicates the estimation of the instantaneous properties. 

\begin{table*}[!ht]
\caption{
\bf{Notation}}
\begin{tabular}{|l|l|}
	\hline
	\textbf{Symbol} & \textbf{Quantity} \\ \hline
	$t$, $n$ & time, continuous and discrete \\ \hline
	$y(t),y(n)$ & test signal, continuous and discrete time \\ \hline
	$r(t), r(n)$ & instantaneous amplitude, continuous and discrete time \\ \hline
	$\phi(t),\phi(n)$ & instantaneous phase, continuous and discrete time \\ \hline
	$h(t)$ & Hilbert kernel ($1/\pi t$) \\ \hline
	$\mathcal{H}$ & Hilbert transform operator \\ \hline
	$z(t)$ & analytic signal \\ \hline
	$\omega(t),\omega(n)$ & instantaneous frequency, continuous and discrete time \\ \hline
	$\mathcal{F}$ & Fourier transform operator \\ \hline
	$f,\omega$ & frequency, Hertz and radians \\ \hline
	$x(t),x(n)$ & oscillatory component of signal, continuous and discrete time \\ \hline
	$x_0(t),x_0(n)$ & offset component of signal, continuous and discrete time \\ \hline
	$\varepsilon(t),\varepsilon(n)$ & signal noise or disturbance, continuous and discrete time \\ \hline	
	$\mathbf{p}_y(n)$ & point at sample $n$ in the phase-plane representation of the signal \\ \hline
	$\mathbf{P}_y(n)$ & vector of points in the arc used to fit the circles \\ \hline
	$n-b$, $n+f$ & samples at the edge of the arc used to fit the circles \\ \hline 
	$\mathbf{p}_f(n)$, $\mathbf{p}_b(n)$ & vectors from point of interest to the leading and trailing edges of arc, respectively (used for finding arc) \\ \hline
	$\theta$ & angle between vectors $\mathbf{p}_b(n)$ and $\mathbf{p}_f(n)$ \\ \hline
	$\psi$ & angle that defines the arc length \\ \hline
	$\mathbf{g}(n)$ & vector in the direction of the estimated tangent to the arc \\ \hline
	$n-b_t$, $n+f_t$ & indexes of the samples that are used to estimate the direction of the tangent to the arc \\ \hline
	$\mathbf{p}_{ft}(n)$, $\mathbf{p}_{bt}(n)$ & vectors from point of interest to the points used to estimate the tangent \\ \hline	
	$\gamma$ & angle between $\mathbf{p}_{ft}(n)$ and $\mathbf{p}_{bt}(n)$ (used for finding tangent) \\ \hline
	$\mathbf{a}(n)$ & normal vector to the tangent of the signal \\ \hline
	$\mathbf{p}_{\hat{x}}(n)$ & phase-plane representation of the oscillatory mode estimate \\ \hline 
	$\mathbf{p}_{\hat{x}_0}(n)$ & phase-plane representation of the offset estimate \\ \hline  
	$\zeta(n)$ & incorrect circle center classifier \\ \hline
	$\rho$ & oversampling parameter \\ \hline
	$f_{max}$ & maximum frequency of interest in the signal \\ \hline
	$T_s$, $F_s$ & sampling period and sampling frequency \\ \hline
	$\beta$, $\alpha$ & incorrect phase transition thresholds \\ \hline 
	$k,K$ & index and total number of intrinsic mode functions \\ \hline
	$\varsigma_k(n)$ & used for estimating the empirical offset \\ \hline
	$s_{max,k}(n)$ & spline through points of $y(n)$ (if $k=1$) or $x_{0,k}(n)$ (if $k>1$) corresponding to maxima of $\varsigma_k(n)$ \\ \hline
	$s_{min,k}(n)$ & spline through points of $y(n)$ (if $k=1$) or $x_{0,k}(n)$ (if $k>1$) corresponding to minima of $\varsigma_k(n)$ \\ \hline
\end{tabular}
\begin{flushleft}This table provides a description of the notation used in this paper.
\end{flushleft}
\label{tab:Notation}
\end{table*}

\dean{This notion of instantaneous frequency allows for the definition of a generalized (Cohen class) time-frequency distribution (TFD)~\cite{Cohen1995}. This provides an estimate of the energy in a particular frequency band at a particular time and is described as
\begin{equation}\label{CohenClassTFD}
\rho \left( {t,f} \right) = \int_{ - \infty }^\infty  {\int_{ - \infty }^\infty  {\int_{ - \infty }^\infty  {{e^{j2\pi v\left( {u - t} \right)}}g\left( {v,\tau } \right)} } } \,z\left( {u + {\raise0.7ex\hbox{$\tau $} \!\mathord{\left/
{\vphantom {\tau  2}}\right.\kern-\nulldelimiterspace}
\!\lower0.7ex\hbox{$2$}}} \right){z^*}\left( {u - {\raise0.7ex\hbox{$\tau $} \!\mathord{\left/
{\vphantom {\tau  2}}\right.\kern-\nulldelimiterspace}
\!\lower0.7ex\hbox{$2$}}} \right){e^{ - j2\pi f\tau }}dvdud\tau,
\end{equation}
where the kernel $g(v,\tau)$ dictates the type of TFD. The simplest case of this TFD is the Wigner-Ville distribution~\cite{Ville1958} (where $g(v,\tau) = 1$) and can be interpreted as the Fourier transform of the autocorrelation of the analytic signal. Importantly, the first moment of the time-frequency distribution corresponds to the Fourier frequency~\cite{Boashash1992}. TFDs of this class are very useful for IF estimates of frequency modulated (FM) signals, but do not provide estimates of the instantaneous phase and amplitude. Therefore, to fully describe instantaneous properties of signals we must use other methods.
}

Amplitude modulations and signal offsets in the time-domain lead to scenarios where the IF estimates are negative, according to the definition in Eq.~\ref{eq:IFdef}. Clearly, for the concept of IF to make sense, it must be positive quantity since the instantaneous phase of a signal should be monotonically increasing with time (except for phase wrapping)~\cite{Huang1998}. To overcome this problem, a band-pass filter is required to extract narrow-band components before calculating the analytic signal. Often this approach is undesirable since most naturally occurring signals do not have a stationary sinusoidal basis. 

The Hilbert-Huang transform (HHT)~\cite{Huang1998} is a method for estimating IP of nonlinear, nonstationary signals. The HHT decomposes a signal into the so-called intrinsic mode functions (IMFs) via a process known as empirical mode decomposition (EMD). The trajectories of IMFs in the complex-plane have an orbit enclosing the origin, guaranteeing that the phase is monotonically increasing in time. Following this, the IP and IF can be defined using the Hilbert transform. The IMFs are extracted by an iterative procedure called `sifting', which can be considered adaptive detrending or demodulating. The sifting algorithm involves finding a cubic spline interpolation through all local minima and another spline through all local maxima, taking the average of the two splines (forming an adaptive trend), and subtracting this away from the original signal. The sifting typically requires several iterations, as the demodulation at each iteration may introduce more extrema from inflections in the signal. The procedure continues until a stopping criterion is met, such that all modulations are removed from the signal (for example, the number of extrema equals the number of zero crossings, or is one less, and the splines are symmetric about the origin). Fig.~\ref{fig:HHTDemo} shows an example of the sifting process to extract the first IMF of the test signal
\begin{equation}\label{eq:FirstTestSig}
y\left( t \right) = a_1\cos \left(2\pi f_1t\right) + a_2\cos \left(2\pi f_2t \right),
\end{equation}
where $f_1 = 7$ Hz, $f_2 = 17$ Hz, $a_1 = f_1^{-1}$ and $a_2=f_2^{-1}$. The example shows the test signal and the three iterations, ordered from top to bottom, that were required to extract the first IMF. The sifting removes modulations and forms narrow-band components~\cite{Huang1998} allowing for estimation of the instantaneous properties using the Hilbert transform. Note, the implementation of the HHT used in all of the examples in this paper was downloaded from the supplementary material of~\cite{Wu2009}. 

The HHT has proved very useful in a range of applications involving nonlinear, nonstationary signal processing (see~\cite{Huang2008,Huang2005a} for reviews), including electroencephalography (EEG) signal analysis~\cite{Wang2008}, nonlinear system identification~\cite{Huang2005b}, and structural health monitoring~\cite{Pai2008}.

An advance in the Hilbert-Huang transform involves normalizing the IMFs (by an approximation of the signal envelope) before computing the Hilbert transform~\cite{Huang2005}. The normalization is designed to separate the amplitude modulated and frequency modulated terms. By removing the IA component (or making it constant), the limitations stated in the Nuttall theorem~\cite{Nuttall1966} are addressed (improving the underestimates of the IF). However, the IF is still underestimated for non-trivial signals. This shortcoming led to the development of the direct quadrature method, where the IP is estimated by simply taking the arccosine of the normalized IMFs. This provides a further improved IF estimate; however, problems occur with the estimation of the phase at time points corresponding to the extrema of the signal if the normalization is greater than unity, which is technically hard to achieve. Nevertheless, this problem can be corrected since the errors only occur at extrema.

A problem with the standard EMD is that it can not deal with noise or disturbances in a consistent manner, where noise and signal may get mixed into the same IMFs~\cite{Wu2009}. This problem is known as intra-mode mixing. The most recent development in the HHT is ensemble empirical mode decomposition (EEMD), which deals with this problem~\cite{Wu2009}. The EEMD is inspired by the noise-added analyses of Flandrin et al.~\cite{Flandrin2005} and Glendhill~\cite{Gledhill2003} and extends findings from other recent studies concerning the statistical properties of the EMD when applied to white noise~\cite{Flandrin2004,Wu2004}. The EEMD defines an IMF as the mean of an ensemble of IMFs, with each member of the ensemble computed from the signal with a different realization of additive white noise. By adding white noise to the signal, the EEMD acts like a dyadic filter bank enabling the correct separation of scales \cite{Flandrin2005a}.
\begin{figure}[ht]
	\centering
		\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/HHTDemoIteration1.eps}
	\label{fig:label1}}
		\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/HHTDemoIteration2.eps}
	\label{fig:label2}}
		\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/HHTDemoIteration3.eps}
	\label{fig:label3}}
		\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/HHTDemoIteration4.eps}
	\label{fig:label4}}
		% \subfigure[]{
		% 		\includegraphics[scale=1]{./Figures/eps/HHTDemoIteration5.eps}
		% 	\label{fig:label5}}
	\label{fig:HHTDemo}
	\caption{Illustration of the sifting procedure of the HHT for extracting the first IMF of the EMD for the test signal of Eq.~\ref{eq:FirstTestSig}. Each subfigure shows an iteration of the sifting procedure. a) The solid black line shows the original signal. The blue dot markers show the local maxima. The blue line shows a cubic spline interpolation through the local maxima. The red dot markers show the local minima. The red line is a cubic spline interpolation through the local minima. The cyan line is the average of the splines, forming an adaptive trend. b) The first iteration of the sifting algorithm. The solid black line is now the signal that has been detrended by the adaptive trend of the original signal. c)-d) The second and third iterations of the sifting algorithm.}
\end{figure}

Despite the usefulness of the HHT there are several issues concerning the interpretation of IMFs. For example, the physical meaning of the IA estimates from the HHT is not clear. This is due to amplitude distortions caused by the iterative sifting process. Furthermore, HHT IMFs are formed by interpolating extrema that may be relatively sparse in time, contradicting the notion of finding local instantaneous properties of a signal. These issues affect the standard HHT, the normalized HHT, the direct quadrature, and EEMD methods since they all involve sifting. 

%Fig.~\ref{fig:HHTAmbiguity} provides an example of where inflection points cause problems for the HHT. For this example, we use the signal 
% \begin{eqnarray}\label{eq:HHTAmbiguityTestSig}
% y\left( t \right) &=& \cos \left( \psi \left( t \right) \right) \\
% \psi \left( t \right) &=& 2\pi ft + \cos \left( {2\pi ft} \right),
% \end{eqnarray}
% where $f=4$~Hz. The example illustrates how the sifting process can yield different results depending on where extrema occur. The inclusion of an extra maxima, by extending the data length by 100 ms (from Fig.~\ref{fig:HHTAmbiguity} B. to C.) changes the demodulation of the inflection points from phase distortions to full oscillations.
% 
% \begin{figure}
%     \centering
%     \includegraphics[scale=0.42]{./Figures/HHTAmbiguity}
%     \caption[HHTAmbiguity]{\textbf{A.} Phase plane representation of the test signal from Eq.~\ref{eq:HHTAmbiguityTestSig}. The upper zero crossing on the $\mathcal{H}y(t)$ axis shows a cusp that is generated by the inflection points in the signal. \textbf{B.} $y(t)$ plotted with the cosine of the instantaneous phase estimate of the first IMF computed with the HHT, $\phi_h(t)$. \textbf{C.} The same test signal and plot the same quantities as B., but $t$ is extended by 0.1~s. The estimate of the instantaneous phase is inconsistent between plots B. and C.}
%     \label{fig:HHTAmbiguity}
% \end{figure}

This paper extends the notion of instantaneous phase, frequency, and amplitude for non-stationary signals through the introduction of the circular phase transform (CPT). The CPT is conceptually related to the HHT in that it uses an adaptive demodulation technique to facilitate estimation of instantaneous signal properties. However, the CPT demodulates the signal in the phase-plane by finding local circle fits, allowing for more accurate phase and amplitude estimates. The paper is laid out as follows. Section~\ref{sect:CPTDescriptionSection} explains the concepts and theory underpinning the CPT. Section~\ref{sect:ComputingCPTSection} describes the procedure for computing the CPT. Section~\ref{sect:Examples} demonstrates the performance of the CPT when applied to a signal with known instantaneous properties in comparison to the methods that employ the EMD. Section~\ref{sect:CPTEMDSection} shows how the CPT can be used to create an EMD that does not rely on the sifting process. %Section~\ref{sect:PhasePlaneCuspsSection} shows how inflections in a time series, or equivalently, phase-plane cusps pose major challenges for estimating IP. Section~\ref{EEGExampleSection} provides a practical example of the CPT EMD using an EEG signal. 
The Discussion and Conclusion follow in Sections~\ref{sect:DiscussionSection} and~\ref{sect:ConclusionSection}, respectively. 

\section{The Circular Phase Transform}\label{sect:CPTDescriptionSection}
The circular phase transform (CPT) is a new method for estimating the instantaneous amplitude (IA), instantaneous phase (IP), and instantaneous frequency (IF) from nonstationary signals. The CPT is an alternative to the HHT that provides improved estimates of the instantaneous properties of signals by obtaining IA and IP estimates that are more local. The CPT models a signal's local trajectory in the phase-plane as an arc of a circle. The circle center provides a new reference point for calculating the IP and IA, thereby providing an adaptive demodulation.

For smooth and continuous oscillatory signals, the local (infinitesimally small) phase-plane trajectory can be described by the arc of a circle. For this class of signal, we can think of the IF as the reciprocal of the time taken to complete the circular orbit at its current rate of change and trajectory (following the arc) in the phase-plane. In other words, it is the best estimate of the IF, since a sinusoid is a circle in the phase-plane. Fourier analysis measures the correlation of the signal in the phase-plane to trajectories of unit circles with a harmonically-related set of frequencies. The CPT estimates circle parameters (radius and center), allowing them to vary at each time sample, thus establishing a basis that is adaptive. In this way, a general platform to establish the notion of IA, IP, and IF is provided.

With sufficient sampling and signal-to-noise ratio, the instantaneous properties described by an arc may be estimated from a discrete time series using circle fitting methods. The uniqueness of the phase-plane representation of a signal is guaranteed if the conditions of the Bedrosian theorem~\cite{Bedrosian1963} are met, and the uniqueness of the IA and IP estimates are inherent in circle fitting methods. In addition, the locally circular representation of the phase-plane trajectory enforces a quadrature structure on the analytic representation of the signal.

The CPT requires the signal to satisfy three conditions in addition to the condition stated by the Bedrosian theorem (Eq.~\ref{eq:BedrosianCondition}). The signal must be 1) smooth and continuous, 2) oscillatory, and 3) mono-component. The third condition allows for physical interpretation of the CPT. A common way to define a signal as being mono-component is to use a particular basis and time scale as a reference~\cite{Boashash1992,Cohen1995}. This definition is not appropriate here since we are dealing with instantaneous quantities, where time-scales may be continuously changing and the basis is arbitrary. Therefore, we define a signal as being mono-component if it can be sufficiently described by a scalar quantity when it is sampled from a vector field. Together, the conditions ensure the signal has an oscillatory component with a phase that is monotonically increasing in time (except at $2\pi$ transitions) and a smooth closed trajectory in the phase-plane. 

Under our standing assumptions, the analytic signal in the phase-plane can be modeled as
\begin{align}\label{eq:SignalModel}
y\left( t \right) &= x\left( t \right) + x_0\left( t \right) + \varepsilon \left( t \right) \\
\mathcal{H}y\left( t \right) &= \mathcal{H}(x\left( t \right) + x_0\left( t \right) + \varepsilon \left( t \right)),
\end{align}
where $x(t) \in \mathbb{R}^1$ is an oscillatory component, $x_0(t) \in \mathbb{R}^1$ denotes an offset (or adaptive trend that is oscillating on a slower time-scale than $x(t)$), and $\varepsilon(t) \sim \mathcal{N}(0,\sigma^2)$ represents process or measurement noise. 

The oscillatory component, $x(t)$, can be thought of as being analogous to the first IMF of the HHT and can be parameterized by IA and IP as
\begin{equation}\label{eq:InstAmplitudeAndPhase}
    x\left( t \right) = r\left( t \right)\cos \left( {\phi \left( t \right)} \right),
\end{equation}
where $r(t)$ denotes the IA and $\phi(t)$ denotes the IP. 

In the noise-free case, 
\begin{align}
	x\left( t \right) &= y\left( t \right) - x_0\left( t \right) \\
	\mathcal{H}x\left( t \right) &= \mathcal{H}\left(y\left( t \right) - x_0\left( t \right)\right)
\end{align}
and the IA is
\begin{equation}\label{eq:IADef}
    r\left( t \right) = \left( x^2(t) + \mathcal{H}x^2(t)\right)^{1/2}.
\end{equation}
For a smooth continuous oscillatory signal, the IA will satisfy
\begin{equation}\label{eq:IAlimitingCase}
\mathop {\lim }\limits_{\tau  \to 0} \left( r\left( t \right) - r\left( t + \tau \right) \right) = 0.
\end{equation}
Naturally, it follows that for a small time interval, $\Delta t$, we have
\begin{equation}\label{eq:IA_small_time_interval}
    r(t)-r(t-\Delta t) < \eta,
\end{equation}
where $\eta \in \mathbb{R}$ is a small constant. Eqs.~\ref{eq:IADef}, \ref{eq:IAlimitingCase}, and \ref{eq:IA_small_time_interval} simply state that, given a sufficiently small segment of data, the local oscillatory component, $x(t)$, can be approximated by an arc of a circle in the phase-plane or, equivalently, a sinusoid in the time domain. In the noise-free case, the IP of $x(t)$ is
\begin{equation}\label{IPdef}
    \phi \left( t \right) = \arctan \left( \frac{\mathcal{H}x\left( t \right)}
    {x\left( t \right)} \right).
\end{equation}
% this bit is commented out because we are not comparing the CPT to the DQ method
% ~~~~~~~~~~~~~~~
% An example of an IF estimate using the CPT is provided in Fig.~\ref{CompareWithDQ}, where we compare the Hilbert-Huang transform, the direct quadrature method (DQ), and the CPT. For this example, we used the test signal 
% \begin{equation}\label{DQTestSignal}
% y(t) = e^{-t/256}\sin\left(\frac{\pi t}{32} + 0.3\sin\left(\frac{\pi t}{32}\right)\right).  
% \end{equation}
% This test signal was chosen since it was used as an example in~\cite{Huang2008} for demonstrating problems of having non-quadrature Hilbert transforms, which results in an underestimate of the IF when using the HHT. The DQ method and the CPT both provide very good IF estimates. The HHT IF estimates are inaccurate due to having a non-quadrature analytic signal for the IMF. The DQ method overcomes the limitations described in the Nuttall theorem via normalizing the IMFs prior to computing the analytic signal. The CPT overcomes the limitations of the Nuttall theorem by enforcing a circular structure in the phase-plane. The DQ method has some minor problems in estimating the IF at points corresponding to extrema of the time-series. This is a consequence of the normalization procedure. 

% ~~~~~~~~~~~~~~~
Modeling the signal trajectory as an arc of a circle in the phase-plane enables the inclusion of a disturbance term, allowing for noise to be accounted for and dealt with in a consistent manner. In addition, since the CPT does not rely on an iterative sifting procedure, meaningful IA estimates are obtained.

% advantage of the CPT method over the HHT is that it does not rely on the sifting process, allowing for inflections to be handled in a more consistent manner. Another 

% this bit is commented out because we are not comparing the CPT to the DQ method
% ~~~~~~~~~~~~~~~
% \begin{figure*}
%   \centering
%   \includegraphics[scale=0.4,angle=-90]{IF_comparison_with_dq}
%   \caption[CompareWithDQ]{\textbf{A.} The test signal described by Eq.~\ref{DQTestSignal}. \textbf{B.} \todo{Remove legend and describe the colors. Add zoomed subplot on RHS. Point out how things are overlapped. Try different line widths for true IF. Discuss glitches with DQ in text and cite the paper.} Illustration of the IF estimates for the CPT, HHT, and DQ methods, compared to the true IF.}
%   \label{CompareWithDQ}
% \end{figure*}
% ~~~~~~~~~~~~~~~

\section{Computing the CPT}\label{sect:ComputingCPTSection}
The steps of the CPT algorithm are presented in Algorithm~\ref{CPTAlgorithm}. The CPT is principally a circle fitting procedure. After computing the Hilbert transform of the signal to get a phase-plane representation, the algorithm consists of three steps for each sample in the time series. 
The first step, described in Section~\ref{sect:FindingArc}, is to find a set of points around each sample to specify an arc of a set length (where the arc length is defined by an angle). The second step, described in Section~\ref{sect:CircleFittingProcedure}, is to fit a circle to each arc, which yields an estimate for the IA and offset for each sample in the time series. These values are used to compute the IP. The third step, described in Section~\ref{sect:DetectingInvalidParameters}, checks the validity of the estimated parameters using prior knowledge of the data structure. Three checks are used: the first check ensures the estimated circle centers (or offsets) are on the correct side of the arc; the second check ensures the IA estimates are bounded by the maximum amplitude of the signal; the final check ensures monotonicity of the IP estimates (except at $2\pi$ phase transitions). After rejecting invalid parameter estimates, the IP is unwrapped and the IF is estimated. Invalid parameters are recovered via interpolation. 

\begin{algorithm}
\caption{The Circular Phase Transform}\label{CPTAlgorithm}
\begin{algorithmic}[1]
\State compute Hilbert transform to find $\mathcal{H}y(t)$
\For {$n=1,2,\hdots, N$}%\comment{All samples in time series}
	\State find indexes $n-b$ and $n+f$ for arc to fit circle
	\State get arc $\mathbf{P}(n) = [\mathbf{p}_y(n-b),\hdots, \mathbf{p}_y(n),\hdots,\mathbf{p}_y(n+f)]$
	\State fit circle to find $\hat{x}_0(n)$ and $\hat{r}(n)$

	\State find indexes $n-b_t$ and $n+f_t$ to estimate tangent 
	\State get tangent estimate $\mathbf{g}(n)= \mathbf{p}_y(n + f_t) - \mathbf{p}_y(n - b_t)$
\EndFor
\State calculate $\hat\phi(n) = \arctan\left(\frac{\mathcal{H}(y(n) - \hat{x}_0(n))}{y(n) - \hat{x}_0(n)}\right)$
\State check validity of circle center estimates using Eq.~\ref{eq:IncorrectSideClassifier}
\State check validity of IA estimate using Eq.~\ref{eq:bound_on_IA_estimate}
\State check validity of IP estimate using Eqs.~\ref{eq:Prior1} and \ref{eq:Prior2}
\State reject invalid parameters estimates
\State unwrap IP estimates
\State estimate IF
\State recover rejected parameters via interpolation
\end{algorithmic}
\end{algorithm}

\subsection{Determining the Arcs for the Circle Fits}\label{sect:FindingArc}
In this section, we describe how the arcs are formed that are used to fit the circles. The set of samples in an arc length specified by the angle $\psi$ about a sample of interest depends on the sampling rate and the frequency content of the data. The set of samples that specify the arc is assumed to be unknown and to vary throughout the time series. Therefore, it must be found empirically.

\begin{figure}[ht]
	\centering
		\includegraphics[scale=1]{./Figures/eps/SetArcLengthDemo.eps}
	\caption{Graphical description of the method to find the arc that is used to fit the circle and the method to find the points that are used to estimate the tangent to the arc. The sinusoidal signal is depicted as the red dashed line, forming the circle in the phase-plane. The point of interest, $\mathbf{p}(n)$, is shown by the blue plus symbol. The arc that is used to fit the circle is shown by the solid red line. The points that mark the leading and trailing edges of the arc, $\mathbf{p}(n+f)$ and $\mathbf{p}(n-b)$, are shown by the red x and $\ast$ markers, respectively. The angle $\theta$ between the lines shown in blue is used to find the specified arc length described by the angle $\psi$. The points that are used to estimate the direction of the tangent to the arc, $\mathbf{p}(n+f_t)$ and $\mathbf{p}(n-b_t)$, are shown by the triangles pointing left and right, respectively. These points are selected using the angle $\gamma$, between the black dashed lines. The normal, $\mathbf{a}(n)$, to the estimated tangent is shown by the solid black line from the origin.}
	\label{fig:SetArcLengthDemo}
\end{figure}

To show how the arcs are formed, we will first consider a noise-free sinusoid of unknown frequency. A graphical representation of the method and the quantities described in this section is provided in Figure~\ref{fig:SetArcLengthDemo}. The sample of interest in the phase-plane representation of the signal can be described in vector form as
\begin{equation}
	\mathbf{p}_y(n) = \left[y\left(n\right),\mathcal{H}y\left(n\right)\right]^{\top}.
\end{equation}
The arc used to fit the circle corresponding to this sample is described by the set of consecutive neighboring points
\begin{equation}
	\mathbf{P}_y(n) = \left[\mathbf{p}_y(n-b),\hdots,\mathbf{p}_y(n),\hdots,\mathbf{p}_y(n+f)\right],
\end{equation}
where $b$ and $f$ are integers that specify the edges of the arc for the sample at $n$. Now we define the vectors that describe the samples at the edges of the arc relative to the sample of interest as
\begin{align}
	\mathbf{p}_b(n) &= \mathbf{p}_y(n-b)-\mathbf{p}_y(n) \\
	\mathbf{p}_f(n) &= \mathbf{p}_y(n+f)-\mathbf{p}_y(n).
\end{align}
The arc length is measured using the angle between these two vectors with
\begin{equation}
	\theta = \arccos\left(\frac{\langle\mathbf{p}_b(n),\mathbf{p}_f(n)\rangle}{\|\mathbf{p}_b(n)\| \|\mathbf{p}_f(n)\|}\right),
\end{equation}
where, for a given $b$ and $f$, the angle describing the arc length, $\hat\psi$, is calculated by
\begin{equation}\label{eq:theta_2_psi}
	\hat\psi = 2(\pi-\theta).
\end{equation}
Note, $\psi$ must be less than $2\pi$ for $\theta$ to be unique.

The specified arc length is found (for each point in the time series) by systematically incrementing $b$ and $f$ until $\hat\psi$ is greater than or equal to $\psi$. If $\hat\psi$ is less than $\psi$, the integers that define the boundary of the arc, $b$ and $f$, are incremented with the constraint that
\begin{equation}\label{eq:balanced_distances}
	\|\mathbf{p}_f(n)\| \approx \|\mathbf{p}_b(n)\|.
\end{equation}
This is achieved by incrementing $f$ if $\|\mathbf{p}_f(n)\| < \|\mathbf{p}_b(n)\|$, or incrementing $b$ if $\|\mathbf{p}_f(n)\| \ge \|\mathbf{p}_b(n)\|$, until $\hat\psi > \psi$. Following this, the arc is approximately symmetric about the sample $\mathbf{p}_y(n)$. 

Now consider a noisy sinusoid. In this case, the measured arc length, $\hat\psi$, may sporadically increase above the specified arc length, $\psi$, due to fluctuations from the disturbance. Therefore, in our implementation, we require $\hat\psi$ to be greater than $\psi$ for multiple consecutive samples. This number of samples is a free parameter that depends on the sampling rate and the SNR of the time series.

Now consider a more complex time series with inflections. In this case, the problem of finding a specified arc length becomes more complicated as inflections in a time series are cusps in the phase-plane representation. At the point of a cusp, the phase-plane trajectory does not follow an arc of a circle and a circle can not be fitted. Therefore, the instantaneous properties of the signal must be estimated by interpolation from neighboring estimates. In addition, the arc used to fit the circle should not be spanning a cusp. Nevertheless, a shorter arc length not spanning the cusp may still provide a good circle fit. If a cusp occurs within the specified arc, then $\theta$ will not be monotonically decreasing as $b$ or $f$ is incremented. Therefore, in noise-free or low-noise cases, cusps can be detected by checking for increases in $\theta$ as $b$ or $f$ are incremented in the same way that the specified arc length is detected. 

\subsection{Circle Fitting Procedure}\label{sect:CircleFittingProcedure}
Many linear and nonlinear least-squares techniques exist for fitting circles to noise-corrupted data. These methods provide estimates of the circle radius and center (see~\cite{Chernov2005} for a review). The circle fitting algorithm that we have applied is the widely accepted Taubin method~\cite{Taubin1991}. This method was chosen due to good performance when using noisy data with small arc lengths.

By estimating a circle that best fits the data segment in a least squares sense, the discrete IA, IP, and IF can be calculated. Provided the circle estimate is accurate, the IP is monotonically increasing in time and the oscillatory component has a phase-plane trajectory that encloses the origin. This allows the IP to be unwrapped unambiguously, where any decrease in the wrapped phase is a $2\pi$ phase transition. An example of the CPT is shown in Fig.~\ref{fig:MappingDemo} using the test signal
\begin{equation}\label{eq:SecondTestSig}
y\left( t \right) = a_1\cos \left(2\pi f_1 t\right) + a_2\cos \left(2\pi f_2 t\right),
\end{equation}
where $f_1 = 7$ Hz, $f_2 = 12$ Hz, $a_1 = 1$ and $a_2=0.7$.

\begin{figure}[ht]
	\centering
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/MappingDemo1.eps}	
	\label{fig:subfiglabel1}}	
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/MappingDemo2.eps}	
	\label{fig:subfiglabel2}}
	\caption{Demonstration of the circular phase transform. a) An example of the transform in the time domain. b) An example of the transform in the phase plane. In both subfigures, the time series, $y(n)$, is plotted in black and the extracted oscillatory component that was found using the CPT, $x(n)$, is plotted in red. The segment of the time series that is used to fit the circle to estimate the IA, IP, and IF for the point shown by the `x' is shown by a thicker black line. The point marked by the `+' on $x(n)$ corresponds to the point marked by `x' on $y(n)$. In b), the point corresponding to the fitted circle center, $x_0(n)$, is shown by the black dot.}\label{fig:MappingDemo}
\end{figure}

\subsection{Detecting Invalid Parameters}\label{sect:DetectingInvalidParameters}
To accurately approximate the phase-plane trajectory of a nonstationary signal by an arc of a circle, it is better to use small segments of data. However, noise has a larger effect on the estimation results when using small arc lengths and fewer points. Therefore, a series of checks is used to help prevent noise induced errors, namely the circle centers being fitted to the incorrect side of the arc, incorrect IA estimates, and incorrect phase progression. 

\subsubsection{Incorrect Circle Center Identification}
Any bounded oscillatory signal will have a closed trajectory in the phase-plane. Therefore, the circle centers (signal offsets) should be confined to one side of the arc that is used to fit the circle. However, errors can occur when fitting circles to noisy data with small arc lengths. Noise may make a concave arc appear to be convex (or vice-versa), resulting in the circle center being mapped to the incorrect side of the arc. A method to detect this is to use an estimate of the local tangent of the signal as a separating line. If candidate circle centers are on the incorrect side of the tangent, they are rejected. 

The direction of the tangent to the phase-plane trajectory of the signal is approximated by 
\begin{equation}
	\mathbf{g}(n) = \mathbf{p}_y(n + f_t) - \mathbf{p}_y(n - b_t),
\end{equation}
where $f_t$ and $b_t$ specify the numbers of samples forward and backward, respectively, from the point of interest. The samples $n + f_t$ and $n-b_t$ are found using the angle between the vectors
\begin{align}
	\mathbf{p}_{ft} = \mathbf{p}_y(n) - \mathbf{p}_y(n + f_t) \\
	\mathbf{p}_{bt} = \mathbf{p}_y(n) - \mathbf{p}_y(n - b_t),
\end{align}
where the angle (see Fig.~\ref{fig:SetArcLengthDemo}) is measured by
\begin{equation}\label{eq:TangentArcLength}
	\gamma = \arccos\left(\frac{\langle\mathbf{p}_{bt}(n),\mathbf{p}_{ft}(n)\rangle}{\|\mathbf{p}_{bt}(n)\| \|\mathbf{p}_{ft}(n)\|}\right).
\end{equation}

To minimize the effect of noise, the points used to estimate the direction of the tangent should be at the edges of an arc length of $\pi$ ($\gamma = \pi/2$) around the point of interest. The points $n+f_t$ and $n+b_t$ are found, such that they are approximately symmetric about $n$, using the method described in Sect.~\ref{sect:FindingArc} for finding the arc to fit the circle. To classify incorrect centers, the normal vector to the tangent is found using a $90$ degree rotation of $\mathbf{g}(n)$,
\begin{equation}
	\mathbf{a}\left(n\right) = \left[\begin{array}{cc}
	0 & -1 \\
	1 & 0\end{array}\right]\mathbf{g}(n).
\end{equation}
The estimated oscillatory component, $\hat{x}(n)$, and the associated circle center (or offset), $\hat{x}_0(n)$, can be written in vector form as
\begin{align}
	\mathbf{p}_{\hat{x}}(n) &= \left[\hat{x}\left(n\right),\mathcal{H}\hat{x}\left(n\right)\right]^{\top} \\ 
	\mathbf{p}_{\hat{x}_0}\left(n\right) &= \left[\hat{x}_0\left(n\right), \mathcal{H}\hat{x}_0\left(n\right)\right]^{\top}. 
\end{align}
Invalid candidate circle centers are detected using 
\begin{equation}
    \zeta(n) = \mathbf{a}\left( n\right)^{\top}\left( \mathbf{p}_{\hat{x}_0}\left( n \right) - \mathbf{p}_{\hat{x}}\left( n\right) \right),
\end{equation}
where an incorrect estimate is detected if
\begin{equation}\label{eq:IncorrectSideClassifier}
    \zeta(n) < 0.
\end{equation} 

If the estimated circle center does not satisfy this condition at a particular point, then the IP and IA cannot be estimated for that sample using this method. The parameters that can not be estimated must be interpolated at the completion of the estimation procedure. 

\subsubsection{Incorrect IA Estimates}
When using small arc lengths to fit circles, errors due to noise may lead to overly large IA estimates. Such errors can be detected by comparing the estimated IA to the amplitude of the signal. A valid IA estimate must satisfy the condition
\begin{equation}\label{eq:bound_on_IA_estimate}
	\hat{r}(n) \leq \max_n\left| y(n) - \bar{y}\right|,
\end{equation}
where $\bar{y}$ is the mean of $y(n)$.

If this condition is not satisfied at a particular sample, then the parameter estimates for that sample are rejected. The parameters that are rejected are recovered by interpolation after all samples are processed. Alternatively, given an accurate IP estimate, the IA can be estimated empirically using the method describing in Section~\ref{sect:CPTEMDSection}.   

\subsubsection{Incorrect Phase Progression}
The candidate circle fits are further constrained using prior information of the phase dynamics. From our fundamental definition, the IP is monotonically increasing in time except at $2\pi$ phase transitions. A phase increment threshold and a phase transition threshold can be derived given knowledge of the sampling rate and the maximum frequency of interest in the signal. To begin the derivation, an oversampling parameter is defined, based on the Nyquist sampling theorem, as
\begin{equation}
	\rho\triangleq\frac{F_s}{2f_{max}},
\end{equation}
where $\rho \in \mathbb{R} \ge 1$, $F_s$ is the sampling frequency, and $f_{max}$ is the maximum frequency of interest in the signal. Under the assumption that the IP estimate at sample $n-1$ is accurate, the phase estimate at sample $n$ should satisfy
\begin{equation}
	0 < \hat\phi(n)-\hat\phi(n-1) < \beta
\end{equation}
where 
\begin{equation}
	\beta = \frac{\pi}{\rho}.
\end{equation}
Now consider the next IP estimate at the sample $n+1$. The increment in the previous estimate is bounded by $\beta$, so the increment in the next estimate must satisfy
\begin{equation}\label{eq:Prior1}
	0 < \hat\phi(n+1)-\hat\phi(n) < 2\beta.
\end{equation} 
At a $2\pi$ phase transition, the maximum phase decrement in radians is
\begin{equation}
	\alpha=2\beta-2\pi,
\end{equation}
where $\alpha$ is a negative number. Following this, the phase difference between consecutive estimates at $2\pi$ transitions should also satisfy
\begin{equation}\label{eq:Prior2}
(\hat{\phi} \left( n \right)+\pi) - (\hat{\phi} \left( n-1\right)+\pi) \le \alpha, 
\end{equation}
where is $\pi$ is added to both terms so they are positive.

If the conditions from Eqs.~\ref{eq:IncorrectSideClassifier}, \ref{eq:bound_on_IA_estimate},~\ref{eq:Prior1}, and~\ref{eq:Prior2} are not satisfied for the previous sample, $n-1$, then parameters corresponding to an earlier sample where the conditions were satisfied, $n-p$, is used. Following this, the thresholds used in Eq.~\ref{eq:Prior1} and~\ref{eq:Prior2} are re-evaluated as
\begin{align}
	\beta_p &= \frac{p\pi}{\rho} \\
	\alpha_p &=2\beta_p-2\pi.
\end{align}
Note that in order for the threshold $\alpha_p$ to be useful, it must be negative. Therefore, there is a limit on the size of $p$ such that
\begin{equation}
	p < 2\rho.
\end{equation}
If $p$ becomes too large then the condition in Eq.~\ref{eq:Prior2} will always be satisfied, effectively resetting the test. If the rate of change for the IP estimates does not satisfy the conditions described above in Eqs.~\ref{eq:Prior1} and \ref{eq:Prior2} for any samples then the parameters are rejected and recovered via interpolation at the completion of the procedure.

In practice, the value of $f_{max}$ may not be known. If this is the case then $f_{max}$ should be set to a value that is conservatively high. This will still provide useful thresholds for detecting erroneous phase changes.

\section{Examples}\label{sect:Examples}
\subsection{Comparison to the HT, HHT, NHT, and DQ}
In this section, a comparison is made between the instantaneous phase estimates of the CPT to the Hilbert transform (HT), Hilbert-Huang transform (HHT), normalized Hilbert transform (NHT), and the direct quadrature (DQ) methods. The standard EMD was used, since the test signal is noise free. The test signal is a chirp with a time varying amplitude described as
\begin{equation}\label{TestSigNoNoise}
    y(n)=r\left(n\right)\cos\left(\phi\left(n\right)\right),
\end{equation}
where the frequency increases linearly from $f_{min}$ = 10 Hz at $n=1$ ($t=0$) to $f_{max}$ = 100 Hz at $n=N$. The sampling rate was 5~kHz and the data length was 300~ms such that $N = 15000$. The test signal is shown in Figure~\ref{fig:TestSig}, where $r(1) = 4$ and linearly decreases to $r(N) = 1$. To alleviate problems associated with boundary effects, the first and last 20~ms of the signal were discarded. Thus, the effective frequency range of the chirp was approximately 16 to 94~Hz. The first IMF of the EMD was used for the comparison since the signal is noise-free, so intra-mode mixing was not a problem. The possibility of $2\pi$ phase wrapping was accounted for when calculating the error.
\begin{figure}[ht]
	\centering
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/TestSigNoiseFreeComparison.eps}
		\label{fig:TestSig}}
	\subfigure[]{	
		\includegraphics[scale=1]{./Figures/eps/NoiseFreeComparison.eps}
		\label{fig:ResultsTestSig}}
	\caption{a) Test signal that was used in the comparisons. The part of the signal shown by the dashed line was discarded. The blue vertical lines mark the three time groups that were used for the comparison of the CPT to the EEMD when noise was added in Sect.~\ref{sect:NoisySignalsSection}. b) Comparison of the IP estimation accuracy between the CPT, HT, HHT, NHT, and the DQ methods. The plot shows the RMSE of the the phase estimates over the duration entire test signal excluding regions discarded for edge effects.}
\end{figure}

For the CPT, the arc length was set to $\psi=3\pi/4$ (for consistency with the next section). The results of the comparison are shown in Figure~\ref{fig:ResultsTestSig}. The figure demonstrates that the net performance in terms of the root mean squared error (RMSE) of the IP estimates of the CPT is superior to the other methods for this test signal.

% The second test signal consisted of the same IP as test signal 1, however the IA was different, where the IA changed in a piece-wise linear fashion such that $r(1)=4$, $r(1500)=1$ and $r(N) = 4$. An example of the test signal can be seen in Figure~\ref{fig:TestSig2}. In the same manner as for test signal 1, the signal was split into 3 time groups to form the comparison.
% 
% \begin{figure}[!ht]
% 	\centering
% 		\includegraphics[scale=1]{./Figures/TestSigForCompFig2.eps}
% 	\caption{Test signal 2 for comparisons. The vertical lines mark the boundaries for different time groups within the signal where comparisons were made. }
% 	\label{fig:TestSig2}
% \end{figure}
% 
% The results for the test signal 2 can be seen in Figure~\ref{fig:ResultsTestSig2}. The results indicate that the CPT does not perform as well as it did for signal 1. This is due to the faster change in the IA, and a bias in the estimation to higher frequencies when the IA and IP is nonstationary. The bias can be understood by considering that lower frequency segments of signals have smaller arc lengths and higher frequency components have larger arc lengths for a given sampling rate. Therefore, when fitting a circle to a segment of data with a changing frequency and amplitude, there will be a bias towards the larger arc length or higher frequency part of the segment. For a slow changing IA this small and for a faster changing IA the bias becomes larger. Nevertheless, this example shows the net error differs by approximately 0.5\% between all methods for this test signal.
% \begin{figure}[!ht]
% 	\centering
% 		\includegraphics[scale=1]{./Figures/IPRMSECompFig2.eps}
% 	\caption{Comparison of the CPT to the HT, HHT, NHT and DQ methods with test signal 2. \textbf{A} show the RMSE of the the phase estimates over the duration entire test signal. \textbf{B} Shows the results for the first time period. \textbf{C} Shows the results for the middle time period. \textbf{D} Shows the results for the last time period.}
% 	\label{fig:ResultsTestSig2}
% \end{figure}
% 
% The third test signal can be seen in Figure~\ref{fig:TestSig3}. The results are shown in Figure~\ref{fig:ResultsTestSig3}. Best the results for the DQ are weird and I can not work out what is going on I will not consider this test signal any further.
% \begin{figure}[!ht]
% 	\centering
% 		\includegraphics[scale=1]{./Figures/TestSigForCompFig3.eps}
% 	\caption{Test signal 3 for comparisons. The vertical lines mark the boundaries for different time groups within the signal where comparisons were made. }
% 	\label{fig:TestSig3}
% \end{figure}
% 
% \begin{figure}[!ht]
% 	\centering
% 		\includegraphics[scale=1]{./Figures/IPRMSECompFig3.eps}
% 	\caption{Comparison of the CPT to the HT, HHT, NHT and DQ methods for signal 3. \textbf{A} show the RMSE of the the phase estimates over the duration entire test signal. \textbf{B} Shows the results for the first time period. \textbf{C} Shows the results for the middle time period. \textbf{D} Shows the results for the last time period.}
% 	\label{fig:ResultsTestSig3}
% \end{figure}

\subsection{Comparison to the EEMD}\label{sect:NoisySignalsSection}

\begin{figure*}[ht]
	\centering
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/NHT_IP_SNR_RMSEa.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/NHT_IP_SNR_RMSEb.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/NHT_IP_SNR_RMSEc.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/CPT_IP_SNR_RMSEd.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/CPT_IP_SNR_RMSEe.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/CPT_IP_SNR_RMSEf.eps}}	
		\caption{Comparison of the EEMD NHT to the CPT IP estimates for the test signal with additive noise. Parts a-c) show results from the NHT using the EEMD. Parts d-f) shows the results from the CPT. Each column shows the results from a particular time group, where the time groups are shown in Fig.~\ref{fig:TestSig}. On each boxplot, the central mark is the median, the edges of the box are the 25th and 75th percentiles, the whiskers extend to the most extreme data points not considered to be outliers, and the outliers are plotted individually as red crosses.}
		\label{fig:RMSEComparison}
\end{figure*}

The performance of the CPT was compared to the ensemble empirical mode decomposition (EEMD) using a noisy test signal. After performing the EEMD, the IP was calculated using the normalized Hilbert transform (EEMD NHT). The test signal from the previous section was used, but with additive Gaussian noise,
\begin{equation}
    y(t)=r\left(t\right)\cos\left(\phi\left(n\right)\right) + \varepsilon \left( n \right),
\end{equation}
where $\varepsilon(n) \sim \mathcal{N}(0,\sigma^2)$. The signal was generated with nine different noise levels, where the standard deviation of the noise was varied from $0$ to $0.56$ in steps of $0.07$. The angle describing the arc length for the circle fitting was set to $\psi=3\pi/4$. The choice of the arc length represents a trade-off between dealing with nonstationarities, where shorter arcs are preferable, and dealing with noise, where longer arcs are preferable. The tangent to the arc that was used for error checking was estimated using $\gamma = \pi/2$ (Eq.~\ref{eq:TangentArcLength}). This provides the maximum distance between the points used to estimate the tangent, which helps to prevent errors associated with noise. The parameters of the EEMD were set such that the noise added to each member of the ensemble had a standard deviation of 0.2 (of the original signal) and each ensemble consisted of 100 realizations, as recommended by the authors of the algorithm~\cite{Wu2009}. 

Since the signal was time-varying, it was split into three time groups, as indicated by the blue vertical lines in Fig.~\ref{fig:TestSig}, to approximate the signal-to-noise ratio (SNR) for benchmarking and comparison. The RMSE of the IP and IA estimates were calculated for 100 realizations of the test signal using the EEMD NHT and the CPT. The calculation of the RMSE for the IP corrected for wrapping between $0$ and $2\pi$, so the maximum possible error was $\pi$. All EEMD IMFs were calculated, since it is not known \emph{a priori} which mode corresponds to the signal. The IMF with lowest RMSE for the middle time group was used for the comparison to ensure that edge effects did not influence the choice of the best IMF corresponding to the signal. 

The comparison between the IP estimation accuracy between the CPT and EEMD for each of the nine noise levels is shown in Fig.~\ref{fig:RMSEComparison}. Subfigures a)-c) show the results for EEMD and d)-f) show the results for the CPT. The error is expressed as a percentage of the maximum possible error, $\pi$. Fig.~\ref{fig:RMSEComparison} shows that the CPT yielded better IP estimates for Group 1 and a comparable performance between the methods for Groups 2 and 3. There are large numbers of outliers for the noisiest conditions for the EEMD NHT due to intra-mode mixing. The results illustrate the effectiveness of the CPT for estimating IP in the presence of noise. As the noise level is increased, the error in the IP estimate slightly increases. This increase in RMSE is related to the number of parameter estimates that were rejected using the checks described in Section~\ref{sect:DetectingInvalidParameters}, where the interpolation used to recover rejected IP estimates was not an exact match to the actual values.

The results for IA estimation are shown in Fig.~\ref{fig:RMSEComparisonSig1_IA}. The error is given as a relative measure with respect to the mean of the actual IA for the respective time periods of each group. For the EEMD, the IA was computed prior to the normalization. The results clearly show the IA estimates of the EEMD were inferior to the CPT. The large errors in the IA estimates for the EEMD were due to the amplitude distortions caused by the iterative sifting process.
\begin{figure*}[ht]
	\centering
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/EEMD_IA_SNR_RMSEa.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/EEMD_IA_SNR_RMSEb.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/EEMD_IA_SNR_RMSEc.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/CPT_IA_SNR_RMSEd.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/CPT_IA_SNR_RMSEe.eps}}
	\subfigure[]{
		\includegraphics[scale=1]{./Figures/eps/CPT_IA_SNR_RMSEf.eps}}	
		\caption{Comparison of the EEMD NHT to the CPT IA estimates from the test signal with additive noise. Parts a-c) show results from the EEMD NHT. Parts d-f) show the results from the CPT. Each column shows the results from a particular time group, where the time groups are shown in Fig.~\ref{fig:TestSig}. On each boxplot, the central mark is the median, the edges of the box are the 25th and 75th percentiles, the whiskers extend to the most extreme data points not considered to be outliers, and the outliers are plotted individually as red crosses.}
		\label{fig:RMSEComparisonSig1_IA}
\end{figure*}

% Figure~\ref{fig:IMFNoNHT} shows a histogram of the IMF indexes for each realization of the test signal for the EEMD. The fifth IMF of the EEMD represented the signal for all of the realizations of the first seven noise levels. For the two highest noise levels, there was also some realizations where the sixth IMF was selected. This is due to intra-mode mixing and explains the outliers in the results for the EEMD \dean{Needs explaining}.   
% \begin{figure}[!ht]\label{fig:IMFNoNHT}
%     \centering
%         \includegraphics[scale=1]{./Figures/IMFNoFigSig1.eps}
%     \caption{IMF index corresponding to the signal.}
% \end{figure}


\section{The CPT for Empirical Mode Decomposition}\label{sect:CPTEMDSection}
For low noise signals, the CPT can be used as an alternative to the sifting process of the EMD. The steps of the CPT EMD algorithm are presented in Algorithm~\ref{CPTEMDAlgorithm} and a graphical description is shown in Fig.~\ref{fig:CPT_EMD}. The CPT EMD models the signal as
\begin{align}
    y(n) &= x_{0,K}(n) + \sum_{k=1}^{K}x_k(n) + \varepsilon(n) \\
    x_k\left(n\right) &= r_k\left(n\right)\cos\left(\phi_k\left(n\right)\right),
\end{align}
where the subscript $k$ indexes the $K$ intrinsic mode functions (IMFs) denoted by $x_k(n)$. The IP, $\phi_k(n)$, is estimated for each IMF using the CPT applied to $y(n)$ (if $k=1$) or the estimated offset, $\hat{x}_{0,k-1}(n)$ (if $k>1$). In the same manner as the EMD, the IMFs are ordered such that the highest frequency component corresponds to the first mode, $k=1$. In the first IMF, we can consider $x_{0,1}(n)$ as a modulation term. If $x_{0,1}(n)$ also has modulations, then it can be decomposed into an oscillatory term, $x_2(n)$, and an offset (another modulating term), $x_{0,2}(n)$. The process is repeated until all $K$ oscillatory modes are extracted from $y(n)$, leaving the final offset term or residual, $x_{0,K}(n)$. The decomposition is complete when an arc of a specified length can no longer be found ($b$ or $f$ become too large) or the amplitude of $x_{0,k}(n)$ becomes too low with respect to $y(n)$.

\begin{algorithm}[ht]
\caption{The CPT for EMD}\label{CPTEMDAlgorithm}
\begin{algorithmic}[1]
\State $k=1$
\State use CPT from Algorithm~\ref{CPTAlgorithm} to estimate $\phi_k(n)$ from $y(n)$
\State find local extrema of $\cos\left(\hat\phi_k(n)\right)$
\State use extrema to form the splines $s_{min,k}(n)$ and $s_{max,k}(n)$
\State calculate $\hat{x}_{0,k}(n) = 0.5\left(s_{min,k}(n) + s_{max,k}(n)\right)$
\While { an arc specified by $\psi$ is found }
    \State $k=k+1$
    \State perform CPT on $\hat{x}_{0,k-1}(n)$ to estimate $\phi_{k}(n)$
    \State repeats steps 3 to 5 to approximate parameters
\EndWhile
\end{algorithmic}
\end{algorithm}

\begin{figure}[ht]
	\centering
	\subfigure[]{\includegraphics[scale=1]{./Figures/eps/CPTEMDDEMOvarsigma1.eps}}
	\subfigure[]{\includegraphics[scale=1]{./Figures/eps/CPTEMDDEMOx1.eps}}
	\subfigure[]{\includegraphics[scale=1]{./Figures/eps/CPTEMDDEMOxx1.eps}}
	\subfigure[]{\includegraphics[scale=1]{./Figures/eps/CPTEMDDEMOvarsigma2.eps}}
	\subfigure[]{\includegraphics[scale=1]{./Figures/eps/CPTEMDDEMOx2.eps}}
	\subfigure[]{\includegraphics[scale=1]{./Figures/eps/CPTEMDDEMOxx2.eps}}
	\caption{Illustration of the CPT EMD method. The same test signal $y(n)$ that was used in Fig.~\ref{fig:HHTDemo} is also used in this example. a) Plot of $\varsigma_1(n)$ with local maxima and minima shown by blue and red dots, respectively. The extrema of $\varsigma_1(n)$ occur at the same times as the extrema of $x_1(n)$. b) The solid back line shows the original test signal, $y(n)$. The blue and red dots show the points in $y(n)$ corresponding to the local maxima and minima of $x_1(n)$, respectively. The blue and red lines show cubic spline interpolations through the points of $y(n)$ that correspond to the maxima and minima of $x_1(n)$, respectively. The cyan line shows the average of the two splines that forms the empirical offset, $x_{0,1}(n)$. c) The first IMF, $x_1(n)$. d) Plot of $\varsigma_2(n)$, showing points that correspond to the extrema of $x_2(n)$. e) The black line shows $x_{0,1}(n)$, the blue and the red lines show the interpolated splines through the points corresponding the extrema of $x_2(n)$. The cyan line shows the empirical offset, $x_{0,2}(n)$. f) The second and final IMF of the decomposition, $x_2(n)$.}
	\label{fig:CPT_EMD}
\end{figure}

The IP and IA can be estimated using the CPT without the requirement of sifting. However, the decomposition also relies on an accurate estimate of the offset, $x_{0,k}(n)$. The estimates of the offset from the circle fitting are generally not good enough to perform the decomposition due to small drifts that add extra extrema. To overcome this problem, the CPT EMD uses an empirical method for estimating the offset that is similar to the standard EMD. It should be noted that the monotonic structure of the IP enables a good estimate of $\phi(n)$, which is exploited in our approach. 

To show how $x_{0,k}(n)$ can be estimated using $\hat\phi_k(n)$, we first define
\begin{equation}
	\varsigma_k(n)=\cos(\hat{\phi}_k(n)).
\end{equation}   
The extrema of the oscillatory mode, $\hat{x}_k(n)$, occur at the same times as the extrema of $\varsigma_k(n)$. Therefore, knowledge of the times where extrema occur in the oscillatory mode only rely on an accurate estimate of the IP. Now consider a noise free signal, $y(n)$. The empirical offset can be estimated by 
\begin{equation}
    \hat{x}_{0,k}(n) = \frac{s_{max,k}(n) + s_{min,k}(n)}{2},
\end{equation}
where $s_{max,k}(n)$ is a cubic spline interpolation through points from $y(n)$ (if $k=1$) or $\hat{x}_{0,k-1}(n)$ (if $k>1$) corresponding to the maxima of $\varsigma_k(n)$, and $s_{min,k}(n)$ is another cubic spline interpolation through points of $y(n)$ (if $k=1$) or $\hat{x}_{0,k-1}(n)$ (if $k>1$) that correspond to minima of $\varsigma_k(n)$. Because the offset is varying on a much slower time-scale than the IP, the empirical method provides a good approximation for low noise signals. If the amplitude of the offset is larger than the noise at the extrema of $y(n)$ or $\hat{x}_{0,k-1}(n)$, then the extrema of $\hat{x}_{0,k}(n)$ occur at the correct time points.

In the standard HHT EMD, the offset, $x_{0,1}(n)$, is approximated by the average of the splines through the extrema of $y(n)$. In contrast, the splines for the CPT EMD are formed using points in $y(n)$ that correspond to extrema of $\hat{x}_1(n)$. This provides an empirical estimate of the offset without the need for sifting. 

Given the empirical offset, an empirical estimate of the IA can also be formed. To show this, we define
\begin{equation}
	\hat{x}_k(n) = \left\{ \begin{array}{ll}
		y(n)-\hat{x}_{0,k}(n), & k=1 \\
		\hat{x}_{0,k-1}(n)-\hat{x}_{0,k}(n), & k>1 
		\end{array}\right.
\end{equation}
and empirical IA is calculated by
\begin{equation}
	\hat{r}_k(n) = \sqrt{(\hat{x}^2_k(n) + \mathcal{H}\hat{x}^2_k(n))}.
\end{equation} 
The empirical IA will typically be smoother than the IA estimate from the circle fit. 
 
An advantage of the CPT EMD over the HHT EMD is that the IA structure is maintained and the IP estimate is not influenced by nonlocal effects of the interpolation in the sifting process. As demonstrated in Section~\ref{sect:NoisySignalsSection}, the CPT can estimate the IP in the presence of disturbances thereby alleviating problems from intra-mode mixing. By combining methods from the HHT and the CPT, an improved and more meaningful EMD is achieved. %This demonstrates the advantage of the CPT EMD method. %An examples of using the CPT with an EEG signal is presented in section~\ref{EEGExampleSection}.
% 

% \section{Examples}
% \subsection{Speech Signal}
% Here we demonstrate how the CPT can be used to analyze speech. We will proceed with a simple example of a person singing `da, da, da, da, da, da, da', increasing in pitch with each `da'. This example was chosen since it is used as an example for demonstrating the HHT, from software publicly available on the Mathworks, Matlab Central File Exchange website~\cite{Tan2008}. This signal provides a good example, as the signal is highly complex, non-stationary, and has different time-frequency scales to study. Fig.~\ref{VoiceDecomp} shows the original signal (9A.) (with no filtering) and the first three IMFs (9C.) of the CPT EMD. The first IMF captures the high frequency details of the signal. As seen in Fig.~\ref{VoiceIMFComparison}, the second IMF captures the fundamental frequency ($F_0$) of the glottal pulses, where the IF steadily increases from approximately 100 Hz in the first `da', to approximately 200 Hz in the final `da'. The third IMF captures the waiver in the $F_0$. This is not the case when using the HHT where inter mode mixing causes problems.
% 
% \begin{figure*}
% \centering
% \includegraphics[scale=0.4]{VoiceSignal.eps}
% \caption[VoiceDecomp]{(Figure needs improvement.) Illustration of the CPT EMD on a speech signal. \textbf{A.} The original times series. The signal is recorded in a person singing `da, da, da, da, da', with the tone increasing with each `da'. \textbf{B.} The FFT of the times series. \textbf{C.} and \textbf{E.} The time series of the first three IMFs calculated using the CPT EMD. \textbf{E.} A detailed plot over a finer region of \textbf{C.}. The the first IMF captures the high frequency details of the speech signal, the second IMF captures the fundamental frequency of speech and the third IMF captures variation in the fundamental frequency. \textbf{D.} and \textbf{F.} The IF estimates of the three IMFs. \textbf{F.} shows the details over a smaller time period for the IF estimates.}
% \label{VoiceDecomp}
% \end{figure*}
% 
% \begin{figure*}
% \centering
% \includegraphics[scale=0.45]{VoiceIMF2Comparison.eps}
% \caption[VoiceIMFComparison]{(Not sure if comparison is fair, as the components may not be equivalent) Comparison of the IF estimates between the HHT EMD and CPT EMD. We compare the second IMF since it represents the fundamental frequency of speech. \textbf{A.} The estimate of the second IMF using the CPT EMD. This shows a clear increase in frequency as the tone of the 'da' increases. \textbf{B.} The second IMF calculated using the HHT EMD. Here we see that the method is not able to capture the detail that was acquired using the CPT.}
% \label{VoiceIMFComparison}
% \end{figure*}
% 
% Cochlear implant speech processing is possible application of this technique. The current model from the leading manufacturer of cochlear implants, Cochlear Ltd., has 22 electrodes implanted in the inner ear. Each electrode is positioned in an area of the cochlea that is sensitive to a different frequency range. For practical reasons only one electrode pair can receive stimulation current at any one time. The choice of the electrode to stimulate is made using speech processing strategies based on Fourier analysis using a filter bank~\cite{Loizou1998}. The CPT EMD offers an alternative where the choice of electrode can be based on the IF estimate and the stimulus activation current based on the IA estimate. The CPT is appropriate for many other signals similar to speech that have periodic aspects with intrawave modulation, that are not well represented by a Fourier basis, and are nonstationary.


\section{Phase Plane Cusps}\label{sect:PhasePlaneCuspsSection}
Perhaps the most challenging aspect of estimating instantaneous properties of signals is dealing with points of inflection in the time series, or equivalently for the CPT, cusps in the phase-plane. The difficulty in dealing with cusps lies in whether to interpret them as full oscillations or phase distortions. To illustrate this point, we define three possible scenarios where cusps occur. The first scenario is due additive noise, the second is due to under sampling of the data, the third occurs when cusps are an intrinsic property of signals. The first scenario is a trivial case and cusps introduced by noise should not be be modeled as full oscillations. To deal with this scenario $Q_{min}$ must be sufficiently large to overcome the noise. Examples of how noise effects the performance of the CPT are shown in Section~\ref{sect:NoisySignalsSection}. In practice, the second case is difficult to distinguish from the third case. Nevertheless, appropriate sampling and filtering as a preprocessing step and choosing an appropriate $Q_{min}$ can alleviate problems in with this scenario. Establishing a consistent procedure for dealing with the third scenario is more challenging. To study this we shall show how a simple mixture of two sinusoids can have intrinsic phase-plane cusps. This example is used to show how the CPT can deal with this case and demonstrate how cusps can be modeled as an oscillation or be treated as a phase distortion. The test signal and its Hilbert transform are defined as
\begin{equation}\label{SamplingSigDef}
    y\left( t \right) = {a_1}\cos \left( {{\omega _1}t} \right) + {a_2}\cos \left( {{\omega _2}t} \right).
\end{equation}   
To study where cusps occur, we first examine loops in the phase-plane that do not enclose the origin. As the signal goes through such a loop, the Hilbert phase slows, stops, reverses, stops again, and then proceeds forward. For the test signal, the time interval where the phase is decreasing (reversing) can be solved analytically by finding the period between stationary points of the Hilbert phase. The stationary points can be found by solving for times where the derivative of the IP is zero. For the test signal, an analytic form of the Hilbert phase can be found. The derivative of the analytic Hilbert phase is 
\begin{eqnarray}
    \frac{d\phi_y(t)}{dt}&=&0.5(\omega_2 + \omega_1) + 0.5(\omega_2 - \omega_1)\frac{a_2^2-a_1^2}{A^2(t)} \\
    A^2(t) &=& a_1^2 + a_2^2 + 2a_1^2a_2^2cos((\omega_2-\omega_1)t).
\end{eqnarray}
The derivative of the Hilbert phase is zero where
\begin{equation}\label{StationaryPhaseTimes}
    t=\frac{1}{\omega_2-\omega_1}\arccos\left(-\frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
    \omega_1)a_1^2a_2^2}\right)+\frac{1}{\omega_2-\omega_1}2\pi k,
\end{equation}
where $k=1,2,...$ and the phase reversal period is (see Appendix~\ref{ReversalPeriodDerivation} for derivation) 
\begin{eqnarray}\label{PhaseReversalPeriod}
    T=\frac{2}{\omega_2-\omega_1}\arccos\left(g\left(a_1,a_2,\omega_1,\omega_2\right)\right) \\ 
g\left(a_1,a_2,\omega_1,\omega_2\right) = \frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
    \omega_1)a_1^2a_2^2}.
\end{eqnarray}
For this test signal the sampling rate, $F_s$, must satisfy
\begin{equation}
    F_s \ge \frac{2}{T}
\end{equation}
to guarantee no cusps will be present. If $g>1$, then it becomes a complex quantity and cusps will be present irrespective of the sampling frequency. These are intrinsic cusps of the signal. If $g=1$ the cusps will be pointed and the CPT will map them as full oscillations. Small errors will occur when the segment used to fit the circle overlaps the point of the cusp. These errors occur because the fitted circle center will be on the incorrect side of the arc at the cusp. These errors will be detected and corrected by the methods explained in Section~\ref{sect:ComputingCPTSection}. However, when $g \gg 1$ the cusps become rounded and the CPT no longer maps them as full oscillations. 

Examples of the CPT mapping for $g<1$, $g=1$ and $g>1$ are shown in Fig.~\ref{Cusps}. The left column of the Figure shows $y(n)$ (plotted with dashed black line) and $x_1(n)$ (in red). The IP estimates in this column where found using $Q=4$. The CPT mapped the small loops (upper plot in column) and the pointed cusps (middle plot) as full oscillations. When the cusp become rounded in the lower plot the CPT was unable to map it as a full oscillation. 

The middle columns shows $y(n)$ plotted with $x_1(n)$, but this time $Q$ was fixed at $110$. The larger segment size has an effect of high pass filtering the phase-plane representation of the data. The upper plot of the column shows that the small loops were not captured by with the larger arc size. However, the lower plot of the column shows the larger arc was able find good fits when the cusps become rounded.
The transition between where cusps are pointed and where they are rounded seems like a good delineator between where they should be modeled by full oscillations and phase distortions. Further work is required to improve mappings to account for transitions from pointed to rounded cusps. 
% \begin{figure*}
%     \centering
%         \includegraphics[scale=0.4]{DemonstrateCusps.eps}
%             \caption[Cusps]{Examples of phase-plane cusps}
%         \label{Cusps}
% \end{figure*}
The examples in Fig.~\ref{Cusps} show that dealing with cusps is challenging. It is important to deal with cusp in a consistent manner, regardless of the method estimating instantaneous properties of signals. Although errors may occur at data segments with rounded cusps, the CPT is consistent in the way it deals with this problem. If possible, data should be high pass filtered, cutting any unwanted low frequency high amplitude components to avoid this problem. This has an effect of contracting these phase-plane representation of the signal, increasing the accuracy of the mapping. By setting a low-pass filter to remove unwanted high frequency components of the signal and set the minimum arc length to half the number of samples in the period of the highest frequency component then the CPT will perform well. 
% 
% \section{Neural Oscillations Example}\label{EEGExampleSection}
% Analysis of instantaneous phase (IP) for EEG signals is an important and expanding area of neuroscientific research, where phase synchronisation has been used to study various forms of cognitive neurodynamics~\cite{Varela2001}. Estimating IP of the brain's rhythms is nontrivial since there highly nonstationary, of a nonlinear origin, has many inflection points and amplitude and frequency modulations. Previously, IP estimates from neural oscillations have been restricted to narrow-band signals. Typically, a narrow pass-band filter is used and the IP is estimated using the Hilbert transform of the filtered signal. Alternatively, the complex Morlet wavelet is commonly used to extract the analytic signal~\cite{LeVanQuyen2001}. Narrow-band filtering has serious consequences that are often overlooked in EEG signal processing. When using narrow-band filtering, one must assume the signal has a sinusoidal basis (or other basis for wavelets). This is obviously not true for signals generated in the brain. Additional problems arise when artifacts or sharp edges occur in signals. The filtered time series will exhibit a ringing from the impulse response of the filter, which will lead to erroneous phase estimates. 
% 
% Fig.~\ref{fig:EEGExample} shows an example of the CPT EMD of an epileptic seizure recorded with intracranial EEG. The data is a referential recording sampled at 4069 Hz from an electrode at the epileptic focus. The data was preprocessed using a median filter ($20^{th}$ order) and low-pass filtered with a cut-off at $95$ Hz. The arc length parameter was set to $\psi=3\pi/2$. The IFs of the decomposed signal show a highly detailed frequency structure.
% 
% The brain's rhythms have specific oscillatory bands that are associated with various cognitive states. For example, phase synchronization of the gamma rhythm (40-90 Hz) between sensory cortices has been implicated as a mechanism for binding of incoming multi-sensory information into a single percept (ref). Also, phase resetting of the alpha rhythm (8-12 Hz) has been implicated in processing sensory information. On a finer scale, phase precession of single neuron theta oscillations (3-8 Hz) has been shown to encode information on navigation and place. Since there is known frequency bands associated with these processes data can be filtered and the CPT can be used as method of correcting phase estimates. 
% \begin{figure*}
% \centering
% \includegraphics[scale=0.4,angle=-90]{EEGExample.eps}
% \caption[EEGExample]{(Figure also needs some improvement) Illustration of the application of the CPT for EEG analysis. \textbf{A}. The EEG time series at the onset of an epileptic seizure. \textbf{B}, \textbf{C} and \textbf{D} show the IF estimates for the first three IMFs (blue dots) and a trend (black dots) calculated using a median filter of order 30. \textbf{B} Highlights the nonstationarity of the frequency content of the spiking discharges. \textbf{C}. Illustrates how the occurrence of epileptic spikes becomes highly regular at 50~s and how the spiking frequency then slowly reduces. \textbf{D} Illustrates the variation in the spiking frequency.}
% \label{fig:EEGExample}
% \end{figure*}
% 
% \begin{figure*}[htbp]
%     \centering
%         \includegraphics[scale=0.4]{EEG_time_freq_fig.eps}
%     \caption{This is the short time histogram of the IF estimate. IF estimates are windowed and then binned. Window overlap is 75 percent and window size is about 1 second. IMFs are ordered from top to bottom. }
%     \label{fig:timefreqplot}
% \end{figure*}
% 
% \begin{figure}[htbp]
%     \centering
%         \includegraphics[scale=.4]{EEGDecompFig.eps}
%     \caption{This figure shows how data is well represented by the IMFs. Just want to show that cusps are present but we can see data is well represented.}
%     \label{fig:EEGdecomp}
% \end{figure}

\section{Discussion}\label{sect:DiscussionSection}

The circular model used by the circular phase transform (CPT) provides an intuitive description of the signal's phase-plane dynamics. The model allows for the introduction of a disturbance term, enabling noise to be dealt with in a consistent manner. Furthermore, circle fitting methods provide statistically optimal parameter estimates~\cite{Al-Sharadqah2009}. An advantage of the CPT empirical mode decomposition (EMD) over the ensemble EMD (EEMD) is that noise does not appear as one of the extracted oscillatory modes. Therefore, unlike the EEMD, the CPT can be used in unsupervised analyses. %In addition, the circular model enforces a quadrature structure to the analytic representation of the signal, thereby over coming the limitations introduced by the Nutall theorem. %An alternative to fitting circles in the phase plane would be to fit sinusoids to windows of the signal. However, this is more difficult because there is more parameters to estimate. 

% Phase synchronization of EEG signals is an important and expanding area of neuroscientific research, and has been used to study various forms of cognitive neurodynamics and disease~\cite{Varela2001}. The frequency properties of the brain are nonstationary, therefore the CPT may be applied to this exciting area of research. Estimating the relationship between IF and IA properties is important in nonlinear identification, particularly systems described by nonlinear oscillators. Since the CPT can estimate the IA our new method may lead to new advancements in this area.
 
Successful implementation of the CPT requires high sampling rates and high signal-to-noise ratios. Nevertheless, good results can be achieved with careful data acquisition and appropriate pre-processing. For accurate results, sampling rates should provide an over-sampling parameter greater or equal to four (four samples in a semi-circle). In the current implementation of the algorithm, errors are unavoidable at phase-plane cusps. These errors can be detected using our proposed methodology and the incorrect IP estimates around the point of a cusp can be recovered accurately by interpolation since the unwrapped phase is monotonically increasing in time. The IP estimates can then be used to recover empirically the other parameters that are varying on a slower time-scale. 

Future work should be directed towards finding an optimal way of choosing the arc length used to fit the circles. This is an important parameter of the algorithm, where for noisy signals it should be set sufficiently large and for fast changing signals set sufficiently small. Other work should be directed to improving estimates around phase-plane cusps and finding improved circle fitting algorithms that are designed specifically for this application.

% \begin{itemize}
%   \item Conditions - most signals will satisfy, interpretation.. measurement
%   \item Mention possible applications.
%   \item Using the CPT as a filter, where we can make random draws around the the point of interest to create a distribution of circle parameters (not sure this random draw will perform at a cusp point).
%   \item We can take our segment so that the current sample starts at the end and translates to the start. This will improve the phase estimates as we approach cusps.  
%   \item Hilbert-Huang transform and its applications By Norden Eh Huang, Samuel S. Shen, has a section on the open problems associated with the hht. I think we address some of them. 
%   \item completeness
% \end{itemize}

\section{Conclusion}\label{sect:ConclusionSection}
We have presented a new method for estimating instantaneous amplitude, phase, and frequency from nonlinear, nonstationary signals. This new approach extends the concepts introduced by the Hilbert-Huang transform, providing more local estimates of the instantaneous phase. We have demonstrated how this new method can be incorporated into the empirical mode decomposition allowing for meaningful estimates of the instantaneous amplitude of intrinsic mode functions. The CPT can be applied to a wide range of signal processing and engineering applications such as nonlinear system identification, structural health monitoring, speech processing, EEG analysis, etc., where the HHT has been used. 

% The results for the second test signal are shown in Figure~\ref{fig:RMSEComparisonSig2}. 
% \begin{figure*}[!ht]\label{fig:RMSEComparisonSig2}
%     \centering
%         \includegraphics[scale=1]{./Figures/SNRcomparisonFigureSig2.eps}
%     \caption{Comparison of the CPT IP estimates to the normalized Hilbert transform for noisy signals. Note; the whiskers show std dev. The red line shows the median, the box cover the data range, except for the outliers shown by red crosses.}
% \end{figure*}


%\section{Instantaneous Amplitude Estimates}
%Perhaps the most significant benefit of using the CPT over the HHT is the ability to extract meaningful IA estimates. To compare the techniques we use a signal that is composed of two sinusoids (from Eq.~\ref{SamplingSigDef} with $f_1 = 7$ Hz, $f_2 = 17$ Hz ($\omega = 2\pi f$) and $a_{1,2} = f_{1,2}^{-1}$ since mixture of sinusoids can be represented as a monocomponent signal with a distorted time varying phase and amplitude.
%\begin{eqnarray}\label{DistortedSinusoids}
%% \nonumber to remove numbering (before each equation)
%  y\left( t \right) &=& {a_1}\cos \left( {{\omega _1}t} \right) + {a_2}\cos \left( {{\omega _2}t} \right) \nonumber \\
%   &=& {a_1}\cos \left( {\left( {\Omega  - \Phi } \right)t} \right) + {a_2}\cos \left( {\left( {\Omega  + \Phi } \right)t} \right) \nonumber \\
%   &=& b\left( t \right)\cos \left( {\Omega t + \Theta \left( t \right)} \right). \nonumber
%\end{eqnarray}
%where
%\begin{eqnarray}
%% \nonumber to remove numbering (before each equation)
%  \Theta \left( t \right) &=& {\arctan}\left( {\frac{{\left( {{a_1} - {a_2}} \right)\tan \left( {\Phi t} \right)}}{{{a_1} + {a_2}}}} \right) \hfill \\
%  b\left( t \right) &=& \sqrt {{a_1}^2 + {a_2}^2 + 2{a_1}{a_2}\cos \left( {2\Phi t} \right)}  \hfill
%\end{eqnarray}
%The term $b(t)$ is a scaled version of the true IA. The scaling is due to the offset being absorbed into the cosine term in eq~\ref{DistortedSinusoids}. Under the assumption that we can estimate the instantaneous phase accurately, we can remove the scaling on $b(t)$ to compare IA estimates by letting
%\begin{equation}\label{RemoveScaling}
%\bar b\left( t \right) = \psi \left( t \right)\left( {b\left( t \right) - \sqrt {{a_1}^2 + {a_2}^2 - 2{a_1}{a_2}} } \right)
%\end{equation}
%\begin{equation}\label{}
%    
%\end{equation}



\appendices
\section{Phase Reversal Period Derivation}\label{ReversalPeriodDerivation}
From Eq.~\ref{StationaryPhaseTimes} to stationary phase times are
\begin{equation}
    t=\frac{1}{\omega_2-\omega_1}\arccos\left(-\frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
    \omega_1)a_1^2a_2^2}\right)+\frac{1}{\omega_2-\omega_1}2\pi k.
\end{equation}
Due to the $2\pi$ periodic nature of $\arccos$ we can also write
\begin{eqnarray}
    t= \left(2\pi - \frac{1}{\omega_2-\omega_1}\arccos\left(-\frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
    \omega_1)a_1^2a_2^2}\right)\right) \\ \nonumber
+\frac{1}{\omega_2-\omega_1}2\pi k.
\end{eqnarray}
The time between the first and second phase reversal is given by
\begin{equation}\label{T}
    T = t_1 - t_2,
\end{equation}
where
\begin{eqnarray}
    t_1 &=& 2\pi - \frac{1}{\omega_2-\omega_1}\arccos\left(-\frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
        \omega_1)a_1^2a_2^2}\right)  \label{t_1} \\
    t_2 &=& \frac{1}{\omega_2-\omega_1}\arccos\left(-\frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
        \omega_1)a_1^2a_2^2}\right). \label{t_2}
\end{eqnarray}
By substituting Eqs.~\ref{t_1} and Eqs.~\ref{t_2} into Eq.~\ref{T} and making simplifications we get Eq.~\ref{PhaseReversalPeriod} as required. 

% (2\pi - \frac {1}{\omega_2-\omega_1}\arccos\left(-\frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
%       \omega_1)a_1^2a_2^2}\right))- \frac{1}{\omega_2-\omega_1}\arccos\left(-\frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
%       \omega_1)a_1^2a_2^2}\right) \\
%       &=& \frac{2}{\omega_2-\omega_1}\left(\pi - \arccos\left(-\frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
%       \omega_1)a_1^2a_2^2}\right) \right) \\
%       &=& \frac{2}{\omega_2-\omega_1}\arccos\left(\frac{a_1^2\omega_1 + a_2^2\omega_2}{(\omega_2 +
%       \omega_1)a_1^2a_2^2}\right)
%   \end{eqnarray}

% use section* for acknowledgement
\section*{Acknowledgments}
This research was funded by the Australian Research Council (Linkage Project LP0560684). DRF thanks Dr. Mark van Rossum for hosting him at the University of Edinburgh and the Harold Mitchell Foundation for a traveling scholarship. Additional thanks go to Stefan Mauger and Kelvin Layton for many helpful discussions and feedback. The Bionic Ear Institute acknowledges the support it receives from the Victorian State Government through the Operational Infrastructure Support Program. 

%\ifCLASSOPTIONcaptionsoff
%  \newpage
%\fi

% references section

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,CPT}


% biography section
%
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{biography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

% \begin{IEEEbiography}{Dean R. Freestone}
% Biography text here.
% \end{IEEEbiography}
% 
% % if you will not have a photo at all:
% \begin{IEEEbiography}{David B. Grayden}
% Biography text here.
% \end{IEEEbiography}
% 
% % insert where needed to balance the two columns on the last page with
% % biographies
% %\newpage
% 
% \begin{IEEEbiography}{Anthony N. Burkitt}
% Biography text here.
% \end{IEEEbiography}
% 
% \begin{IEEEbiography}{Alan Lai}
% Biography text here.
% \end{IEEEbiography}
% 
% \begin{IEEEbiography}{Tim Nelson}
% Biography text here.
% \end{IEEEbiography}
% 
% \begin{IEEEbiography}{Levin Kuhlman}
% Biography text here.
% \end{IEEEbiography}

% that's all folks
\end{document} 